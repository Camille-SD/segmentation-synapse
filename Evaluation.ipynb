{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.modules.loss import CrossEntropyLoss\n",
    "import torch.optim as optim\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from nnmodule import PatchEmbed, Block, ResidualConnection, UpSampleBlock, DoubleConvolution, DownSampleBlock, Deconv, DoubleConv, VisionTransformer, load_custom_model\n",
    "from models import UNet, UNETR\n",
    "import utils\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, unique_in_channel=False):\n",
    "    db_test = utils.Synapse_dataset(base_dir='./Synapse/test_vol_h5/', list_dir='./lists_Synapse', split=\"test_vol\")\n",
    "    testloader = DataLoader(db_test, batch_size=1, shuffle=False, num_workers=0)\n",
    "    logging.info(\"{} test iterations per epoch\".format(len(testloader)))\n",
    "    print(\"{} test iterations per epoch\".format(len(testloader)))\n",
    "    model.eval()\n",
    "    metric_list = 0.0\n",
    "    for i_batch, sampled_batch in enumerate(testloader):\n",
    "        h, w = sampled_batch[\"image\"].size()[2:]\n",
    "        image, label, case_name = sampled_batch[\"image\"], sampled_batch[\"label\"], sampled_batch['case_name'][0]\n",
    "        metric_i = test_single_volume(image, label, model, classes=9, patch_size=[224, 224], uic=unique_in_channel)\n",
    "        metric_list += np.array(metric_i)\n",
    "        logging.info('idx %d case %s mean_dice %f mean_hd95 %f' % (i_batch, case_name, np.mean(metric_i, axis=0)[0], np.mean(metric_i, axis=0)[1]))\n",
    "        print('idx %d case %s mean_dice %f mean_hd95 %f' % (i_batch, case_name, np.mean(metric_i, axis=0)[0], np.mean(metric_i, axis=0)[1]))\n",
    "    metric_list = metric_list / len(db_test)\n",
    "    for i in range(1, 9):\n",
    "        logging.info('Mean class %d mean_dice %f mean_hd95 %f' % (i, metric_list[i-1][0], metric_list[i-1][1]))\n",
    "        print('Mean class %d mean_dice %f mean_hd95 %f' % (i, metric_list[i-1][0], metric_list[i-1][1]))\n",
    "    performance = np.mean(metric_list, axis=0)[0]\n",
    "    mean_hd95 = np.mean(metric_list, axis=0)[1]\n",
    "    logging.info('Testing performance in best val model: mean_dice : %f mean_hd95 : %f' % (performance, mean_hd95))\n",
    "    print('Testing performance in best val model: mean_dice : %f mean_hd95 : %f' % (performance, mean_hd95))\n",
    "    return \"Testing Finished!\"\n",
    "\n",
    "def test_single_volume(image, label, net, classes, patch_size=[256, 256], uic):\n",
    "    image, label = image.squeeze(0).cpu().detach().numpy(), label.squeeze(0).cpu().detach().numpy()\n",
    "    if len(image.shape) == 3:\n",
    "        prediction = np.zeros_like(label)\n",
    "        for ind in range(image.shape[0]):\n",
    "            slice = image[ind, :, :]\n",
    "            x, y = slice.shape[0], slice.shape[1]\n",
    "            if x != patch_size[0] or y != patch_size[1]:\n",
    "                slice = zoom(slice, (patch_size[0] / x, patch_size[1] / y), order=3)  # previous using 0\n",
    "            input = torch.from_numpy(slice).unsqueeze(0).unsqueeze(0).float().cuda()\n",
    "            net.eval()\n",
    "            with torch.no_grad():\n",
    "                if uic == False:\n",
    "                    input = input.expand(-1, 3, -1, -1)\n",
    "                outputs = net(input)\n",
    "                out = torch.argmax(torch.softmax(outputs, dim=1), dim=1).squeeze(0)\n",
    "                out = out.cpu().detach().numpy()\n",
    "                if x != patch_size[0] or y != patch_size[1]:\n",
    "                    pred = zoom(out, (x / patch_size[0], y / patch_size[1]), order=0)\n",
    "                else:\n",
    "                    pred = out\n",
    "                prediction[ind] = pred\n",
    "    else:\n",
    "        input = torch.from_numpy(image).unsqueeze(\n",
    "            0).unsqueeze(0).float().cuda()\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            out = torch.argmax(torch.softmax(net(input), dim=1), dim=1).squeeze(0)\n",
    "            prediction = out.cpu().detach().numpy()\n",
    "    metric_list = []\n",
    "    for i in range(1, classes):\n",
    "        metric_list.append(utils.calculate_metric_percase(prediction == i, label == i))\n",
    "\n",
    "    return metric_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(depth=4, input_size=[1], num_classes=9, dilation=2).to(DEVICE)\n",
    "model.load_state_dict(torch.load(\"UNet_4_dilation2_epoch_50.pth\"))\n",
    "inference(model)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
