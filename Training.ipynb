{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.modules.loss import CrossEntropyLoss\n",
    "import torch.optim as optim\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from nnmodule import PatchEmbed, Block, ResidualConnection, UpSampleBlock, DoubleConvolution, DownSampleBlock, Deconv, DoubleConv, VisionTransformer, load_custom_model\n",
    "from models import UNet, UNETR\n",
    "import utils\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = './Synapse/train_npz/'\n",
    "LIST_DIR = './lists_Synapse'\n",
    "NUM_CLASSES = 9\n",
    "\n",
    "db_train = utils.Synapse_dataset(base_dir=TRAIN_DIR, list_dir=LIST_DIR, split=\"train\",\n",
    "                            transform=transforms.Compose([utils.RandomGenerator(output_size=[224, 224])]))\n",
    "\n",
    "trainloader = DataLoader(db_train, batch_size=24, shuffle=True, num_workers=0, pin_memory=True)\n",
    "ce_loss = CrossEntropyLoss()\n",
    "dice_loss = utils.DiceLoss(NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model \n",
    "\n",
    "'''\n",
    "model = UNet(depth=4, input_size=[1], num_classes=9, dilation=2).to(DEVICE)\n",
    "model = UNETR(depth=6, skip_connections=[2,5], pretrained_name='vit_base_patch16_224', num_classes=9).to(DEVICE)\n",
    "'''\n",
    "\n",
    "model = UNETR(depth=12, skip_connections=[2,5,8,11], pretrained_name='vit_base_patch16_224', num_classes=9).to(DEVICE)\n",
    "\n",
    "USE_3_CHANNELS = False\n",
    "\n",
    "base_lr = 0.01\n",
    "optimizer = optim.SGD(model.parameters(), lr=base_lr, momentum=0.9, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 100\n",
    "max_iterations = max_epoch * len(trainloader)\n",
    "best_performance = 0.0\n",
    "\n",
    "# Training loop\n",
    "\n",
    "iter_num = 0\n",
    "\n",
    "for epoch_num in range(max_epoch):\n",
    "    for i_batch, sampled_batch in enumerate(trainloader):\n",
    "        image_batch, label_batch = sampled_batch['image'], sampled_batch['label']\n",
    "        image_batch, label_batch = image_batch.cuda(), label_batch.cuda()\n",
    "\n",
    "        if USE_3_CHANNELS:\n",
    "            image_batch = image_batch.expand(-1, 3, -1, -1)\n",
    "\n",
    "        outputs = model(image_batch)\n",
    "        loss_ce = ce_loss(outputs, label_batch[:].long())\n",
    "        loss_dice = dice_loss(outputs, label_batch, softmax=True)\n",
    "        loss = 0.5 * loss_ce + 0.5 * loss_dice\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_ = base_lr * (1.0 - iter_num / max_iterations) ** 0.9\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr_\n",
    "        iter_num = iter_num + 1\n",
    "        \n",
    "    save_interval = 50 \n",
    "    if (epoch_num + 1) % save_interval == 0:\n",
    "        save_mode_path = os.path.join('epoch_' + str(epoch_num + 1) + '.pth')\n",
    "        torch.save(model.state_dict(), save_mode_path)\n",
    "        logging.info(\"save model to {}\".format(save_mode_path))\n",
    "\n",
    "if epoch_num >= max_epoch - 1:\n",
    "    save_mode_path = os.path.join('epoch_' + str(max_epoch) + '.pth')\n",
    "    torch.save(model.state_dict(), save_mode_path)\n",
    "    logging.info(\"save model to {}\".format(save_mode_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
